{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eed39b54",
   "metadata": {},
   "source": [
    "**PHASE 1: DATA PREPROCESSING - Text Cleaning**\n",
    "\n",
    "Purpose: Clean abstracts for TF-IDF vectorization  \n",
    "Input: arxiv_metadata_features.pkl  \n",
    "Output: arxiv_text_cleaned.pkl  \n",
    "Cleaning: Lowercase, remove special chars, normalize whitespace  \n",
    "Columns Kept: id, title, abstract_clean, year, categories, metadata  \n",
    "ML Involved: None - Text preprocessing  \n",
    "Runtime: ~10-15 minutes  \n",
    "Run Once: Never need to run again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f29309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 2,384,622 papers\n",
      "Columns: ['id', 'title', 'abstract', 'year', 'primary_category', 'all_categories', 'top_level_domain', 'num_categories', 'is_multi_category', 'has_journal', 'num_authors', 'abstract_length', 'title_length']\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# enable progress bar for pandas\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971ad288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load metadata\n",
    "\n",
    "df = pd.read_pickle('data/processed/arxiv_metadata_features.pkl')\n",
    "print(f\"Loaded: {len(df):,} papers\")\n",
    "print(f\"Columns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c653e740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "  A fully differential calculation in perturbative quantum chromodynamics is\n",
      "presented for the production of massive photon pairs at hadron colliders. All\n",
      "next-to-leading order perturbative contributi\n",
      "\n",
      "Cleaned:\n",
      "a fully differential calculation in perturbative quantum chromodynamics is presented for the production of massive photon pairs at hadron colliders all next to leading order perturbative contributions\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "\n",
    "    \"\"\"\n",
    "    clean abstract text for TF-IDF\n",
    "    - lowercase\n",
    "    - remove special characters\n",
    "    - remove extra whitespace\n",
    "    \"\"\"\n",
    "\n",
    "    if pd.isna(text) or text == '':\n",
    "        return \"\"\n",
    "    \n",
    "    # convert to string and lowercase\n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # remove special characters, keep only letters and spaces\n",
    "    text = re.sub(r'[^a-z\\s]', ' ', text)\n",
    "    \n",
    "    # remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# test on one abstract\n",
    "\n",
    "sample_text = df['abstract'].iloc[0]\n",
    "print(\"Original:\")\n",
    "print(sample_text[:200])\n",
    "print(\"\\nCleaned:\")\n",
    "print(clean_text(sample_text)[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3387db87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning abstracts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2384622/2384622 [00:55<00:00, 43192.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original abstract length: 1020 chars\n",
      "Cleaned abstract length: 983 chars\n",
      "Empty abstracts: 0\n"
     ]
    }
   ],
   "source": [
    "# clean abstracts (this could take ~10-15 minutes)\n",
    "\n",
    "print(\"Cleaning abstracts...\")\n",
    "df['abstract_clean'] = df['abstract'].progress_apply(clean_text)\n",
    "\n",
    "# check results\n",
    "\n",
    "print(f\"\\nOriginal abstract length: {df['abstract_length'].mean():.0f} chars\")\n",
    "print(f\"Cleaned abstract length: {df['abstract_clean'].str.len().mean():.0f} chars\")\n",
    "print(f\"Empty abstracts: {(df['abstract_clean'] == '').sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06399533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean titles too (might use for visualization later)\n",
    "\n",
    "print(\"Cleaning titles...\")\n",
    "df['title_clean'] = df['title'].progress_apply(clean_text)\n",
    "\n",
    "print(f\"Empty titles: {(df['title_clean'] == '').sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ff7cf48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 papers with no abstract\n",
      "Remaining: 2,384,622 papers\n"
     ]
    }
   ],
   "source": [
    "# remove papers with empty abstracts after cleaning\n",
    "\n",
    "df_before = len(df)\n",
    "df = df[df['abstract_clean'] != ''].reset_index(drop=True)\n",
    "df_after = len(df)\n",
    "\n",
    "print(f\"Removed {df_before - df_after:,} papers with no abstract\")\n",
    "print(f\"Remaining: {df_after:,} papers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "404d6677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved to: data/processed/arxiv_text_cleaned.pkl\n",
      "Memory: 5.70 GB\n"
     ]
    }
   ],
   "source": [
    "# save cleaned data\n",
    "\n",
    "df.to_pickle('data/processed/arxiv_text_cleaned.pkl')\n",
    "print(f\"✓ Saved to: data/processed/arxiv_text_cleaned.pkl\")\n",
    "print(f\"Memory: {df.memory_usage(deep=True).sum() / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e84f76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓✓✓ Success! ✓✓✓\n",
      "File size: 4.88 GB\n",
      "Papers: 2,384,622\n",
      "Columns: ['id', 'title', 'abstract', 'year', 'primary_category', 'all_categories', 'top_level_domain', 'num_categories', 'is_multi_category', 'has_journal', 'num_authors', 'abstract_length', 'title_length', 'abstract_clean']\n",
      "\n",
      "Sample cleaned abstract:\n",
      "a fully differential calculation in perturbative quantum chromodynamics is presented for the production of massive photon pairs at hadron colliders all next to leading order perturbative contributions from quark antiquark gluon anti quark and gluon gluon subprocesses are included as well as all orde\n"
     ]
    }
   ],
   "source": [
    "# verify\n",
    "\n",
    "pickle_path = 'data/processed/arxiv_text_cleaned.pkl'\n",
    "\n",
    "if os.path.exists(pickle_path):\n",
    "    size_gb = os.path.getsize(pickle_path) / 1024**3\n",
    "    print(f\"✓✓✓ Success! ✓✓✓\")\n",
    "    print(f\"File size: {size_gb:.2f} GB\")\n",
    "    \n",
    "    # Quick check\n",
    "    df_check = pd.read_pickle(pickle_path)\n",
    "    print(f\"Papers: {len(df_check):,}\")\n",
    "    print(f\"Columns: {list(df_check.columns)}\")\n",
    "    print(f\"\\nSample cleaned abstract:\")\n",
    "    print(df_check['abstract_clean'].iloc[0][:300])\n",
    "else:\n",
    "    print(\"x Not saved yet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f1995e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: (2384622, 14)\n",
      "Columns before: ['id', 'title', 'abstract', 'year', 'primary_category', 'all_categories', 'top_level_domain', 'num_categories', 'is_multi_category', 'has_journal', 'num_authors', 'abstract_length', 'title_length', 'abstract_clean']\n",
      "\n",
      "After: (2384622, 13)\n",
      "Columns after: ['id', 'title', 'abstract_clean', 'year', 'primary_category', 'all_categories', 'top_level_domain', 'num_categories', 'is_multi_category', 'has_journal', 'num_authors', 'abstract_length', 'title_length']\n",
      "Removed 1 columns\n",
      "Memory: 3.32 GB\n",
      "\n",
      "✓ Saved optimized version\n"
     ]
    }
   ],
   "source": [
    "# quick clean up\n",
    "\n",
    "# keep what we need for clustering and analysis\n",
    "# using keep rather than drop to keep overview of current columns\n",
    "\n",
    "keep_columns = [\n",
    "    'id',                    # paper identifier\n",
    "    'title',                 # original title (for display in analysis)\n",
    "    'abstract_clean',        # clean abstract (for TF-IDF) - MAIN FEATURE\n",
    "    'year',                  # temporal analysis\n",
    "    'primary_category',      # main category\n",
    "    'all_categories',        # full category list\n",
    "    'top_level_domain',      # cs, math, physics, etc.\n",
    "    'num_categories',        # how many categories\n",
    "    'is_multi_category',     # multi-category flag\n",
    "    'has_journal',           # published or preprint (quality signal)\n",
    "    'num_authors',           # collaboration size\n",
    "    'abstract_length',       # original length (before cleaning)\n",
    "    'title_length'           # original title length\n",
    "]\n",
    "\n",
    "df_check = pd.read_pickle('data/processed/arxiv_text_cleaned.pkl')\n",
    "print(f\"Before: {df_check.shape}\")\n",
    "print(f\"Columns before: {list(df_check.columns)}\")\n",
    "\n",
    "# Keep only needed columns\n",
    "df_final = df_check[keep_columns].copy()\n",
    "\n",
    "print(f\"\\nAfter: {df_final.shape}\")\n",
    "print(f\"Columns after: {list(df_final.columns)}\")\n",
    "print(f\"Removed {len(df_check.columns) - len(keep_columns)} columns\")\n",
    "print(f\"Memory: {df_final.memory_usage(deep=True).sum() / 1024**3:.2f} GB\")\n",
    "\n",
    "# Save final version\n",
    "df_final.to_pickle('data/processed/arxiv_text_cleaned.pkl')\n",
    "print(\"\\n✓ Saved optimized version\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
